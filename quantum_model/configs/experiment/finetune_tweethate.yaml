# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: bert_qml_finetune.yaml
  - override /model: bert_qml_finetune.yaml
  - override /trainer: bert_qml_finetune.yaml
  - override /logger: wandb_finetune.yaml
  - override /callbacks: model_checkpoint.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters
#ckpt_path: ${hydra:runtime.cwd}/logs/train/runs/mnli/qbert/qi4megld/checkpoints/epoch=52-step=81302.ckpt
seed: 12345
dataset: tweethate

qubits: 5
fold: 0

train: True
test: False

trainer:
  min_epochs: 1
  max_epochs: 20
  devices: 1

callbacks:
  model_checkpoint:
    dirpath: "model/ckpt-QCBERT-${qubits}qubit-${dataset}-bs32-fold_${fold}-no_clean-lr43/"
    filename: "qbert-{epoch:02d}-{global_step}-{val_loss:.3f}" # checkpoint filename
    monitor: val_loss # name of the logged metric which determines when model is improving
  

data:
  _target_: src.data.tweethate_datamodule.tweethate_DataModule
  #_target_: src.data.OLID_datamodule.OLID_DataModule
  task_name: ${dataset}
  dataset_path: "TwitterHate_5fold_no_clean/"
  fold_num: ${fold}
  

model:
  _target_: src.models.qml_bert_finetune_module.TransformerLitModule
  task_name: ${dataset}
  learning_rate: 4e-3
  text_save_dir: "output_file/QCBERT-lr43/"
  fold_num: ${fold}
  encoder_trainable: false
  projection_trainable : true
  n_unitary_circuit_layers : 5
  config_path: ${hydra:runtime.cwd}/model_configs/qbert_${qubits}qubit_10/config.json
  checkpoint_path: ${hydra:runtime.cwd}/model/checkpoints-continue-pretrain-5qubit-bs64-EncoderTrainable-10depth/qbert-epoch=113-global_step=0-train_loss=1.84.ckpt
  
logger:
  wandb:
    #name: "${qubits}qubit-finetune-${dataset}-BERT+QCLS-20depth"
    name: "${qubits}qubit-${dataset}-noisyQCBERT-${fold}-10depth-5U-lr43_no_clean"
    #name: "${qubits}qubit-finetune-${dataset}-BERT-lr55"
    #name: "${qubits}qubit-finetune-${dataset}-wo-20depth-5U-lr3"
    #save_dir: "${paths.output_dir}/${dataset}"
  csv:
    name: "csv/${dataset}/"
